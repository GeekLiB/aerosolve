# Example of using the generic pipeline for binary classification.
#
# Sample data are from this census dataset:
# https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names
#
# The goal is to predict whether a person makes over $50k in yearly income.
#

job_name : "Generic Pipeline"

# Settings as to where the data goes
training_data_version : 1
model_version: "a"

# Which model config to use
model_type : "linear"
model_config : ${model_type}"_model_config"
demo_table : "pricing.income_training_raw"
# Can use a different table
demo_table_eval : "pricing.income_training_raw"


# Where to dump data; change prefix based on your HDFS directory layout
prefix : "hdfs://airfs-silver/user/"${USER}"/demo_pipeline"
training_data : ${prefix}"/training_data"${training_data_version}
eval_data : ${prefix}"/eval_data"${training_data_version}

eval_output : ${prefix}"/eval_output/"${training_data_version}_${model_version}".eval"
model_name : ${prefix}"/model/"${training_data_version}_${model_version}_${model_type}".model"
model_dump : ${model_name}".tsv"
forest_model_dump: ${model_name}".dot"
calibrated_model_name : ${prefix}"/calibrated_model/"${training_data_version}_${model_version}".model"
scoring_output : ${prefix}"/scores/"${training_data_version}

train_subsample : 0.1
eval_subsample : 0.1
training_fraction : 0.9

# The convention is to name features FAMILY_SHORTNAME
# The reason for feature families is so we can apply transforms to multiple, related features
# at a time.
#
# By default two families are created:
# (1) BIAS, B and
# (2) MISS, COLUMN_NAME for missing features
#
# The exception is a special feature named "LABEL" which has to be a float.
#
# For the example query, we use two families, "i" for numeric features and "s" for string ones.
generic_hive_query : """
  select
    if(LENGTH(label)=5, -1, 1) as LABEL,
    age as i_age,
    workclass as s_workclass, fnlwgt as s_fnlwgt,
    education as s_education,
    education_num as i_educationnum,
    marital_status as s_marital,
    occupation as s_occupation,
    relationship as s_relationship,
    race as s_race, sex as s_sex,
    capital_gain,
    capital_loss,
    hours_per_week as i_hours,
    native_country as s_country
"""
# To use a CSV as a data source instead of Hive, create a temporary table using the
# databricks spark-csv library and then write a query against that table. Here's an example:
#
#  create temporary table tmp_income_training
#  using com.databricks.spark.csv
#  options (
#  path          "file:///home/my_username/my_data_file.csv",
#  header        "true",
#  inferSchema   "true"
#  );
#  select
#    if(LENGTH(label)=5, -1, 1) as LABEL,
#    age as i_age,
#    workclass as s_workclass, fnlwgt as s_fnlwgt,
#    education as s_education,
#    ...
#  from tmp_income_training;

debug_example {
  hive_query : ${generic_hive_query}" from "${demo_table}
  count : 10
}

debug_transforms {
  hive_query : ${generic_hive_query}" from "${demo_table}
  model_config : ${model_config}
  count : 3
}

make_training {
  training_hive_query : ${generic_hive_query}" from "${demo_table}
  training_output : ${training_data}
  # Eval data is optional
  eval_hive_query : ${generic_hive_query}" from "${demo_table_eval}
  eval_output : ${eval_data}

  num_shards : 20
}

train_model {
  input : ${training_data}
  subsample : ${train_subsample}
  model_config : ${model_config}
  downsample: [ "-1:0.1" ]
  training_fraction : ${training_fraction}
}

eval_model {
  input : ${eval_data}
  subsample : ${eval_subsample}
  bins : 5
  model_config : ${model_config}
  is_probability : false
  is_regression : false
  metric_to_maximize : "!HOLD_F1"
  model_name : ${model_name}
  training_fraction : ${training_fraction}
}

calibrate_model {
  model_config : ${model_config}
  model_name : ${model_name}
  calibrated_model_output : ${calibrated_model_name}
  input: ${training_data}
  learning_rate : 0.01
  rate_decay : 0.95
  iterations : 100
  num_bags : 10
  tolerance : 0.01
  subsample : 0.5
  training_fraction : ${training_fraction}
}

eval_model_calibrated {
  input : ${training_data}
  subsample : ${eval_subsample}
  bins : 5
  model_config : ${model_config}
  is_probability : true
  metric_to_maximize : "!HOLD_F1"
  model_name : ${calibrated_model_name}
}

dump_model {
  model_name : ${model_name}
  model_dump : ${model_dump}
}

dump_model_to_hive {
  model_name : ${model_name}
  model_dump : "hdfs://hdfs/team//model_coefficient_spline_values/model=xxx"
  overwrite : true
}

dump_forest {
  model_name : ${model_name}
  model_dump : ${forest_model_dump}
}

score_table {
  model_config : ${model_config}
  model_name : ${calibrated_model_name}
  hive_query : ${generic_hive_query}", id as UNIQUE_ID from pricing.income_training_ids"
  num_shards : 20
  output : ${scoring_output}
}

debug_score_table {
  model_config : ${model_config}
  model_name : ${calibrated_model_name}
  hive_query : ${generic_hive_query}", id as UNIQUE_ID from pricing.income_training_ids"
  count : 10
}

identity_transform {
  transform : list
  transforms : [ ]
}

quantize_capital {
  transform : multiscale_quantize
  field1 : "capital"
  output : "capital"
  buckets : [500, 2000]
}

move_age {
  transform : multiscale_move_float_to_string
  field1 : "i"
  keys: [
    "age"
  ]
  output : "A"
  buckets : [5.0]
}

move_hours {
  transform : multiscale_move_float_to_string
  field1 : "i"
  keys: [
    "hours"
  ]
  output : "A"
  buckets : [5.0]
}

move_edu {
  transform : multiscale_move_float_to_string
  field1 : "i"
  keys: [
    "educationnum"
  ]
  output : "A"
  buckets : [3.0]
}

combined_transform {
  transform : list
  transforms : [
    "quantize_capital"
    "move_age"
    "move_hours"
    "move_edu"
  ]
}

# Config for a linear product quantization model. This model is heavily
# dependent upon feature transforms being set up correctly as it only
# handles discrete (i.e., string) features and all float features
# have to be quantized. This is so that we can debug the model easily.
linear_model_config {
  trainer : "linear"
  prior : [
    "BIAS,B,0.0", # Set the priors using feature family, feature name, initial weight
  ]
  model_output : ${model_name}
  rank_key : "LABEL"
  loss : "hinge"
  margin : 1.0
  rank_threshold : 0.5
  dropout : 0.1
  learning_rate : 0.01
  num_bags : 10
  iterations : 10
  lambda : 0.001
  lambda2 : 0.01
  context_transform : identity_transform
  item_transform : identity_transform
  combined_transform : combined_transform
}

# Forest of trees model. Less feature engineering needed but less debuggable.
# Use this if you just want something fast and easy to use.
forest_model_config {
  trainer : "forest"
  model_output : ${model_name}
  rank_key : "LABEL"
  loss : "gini",
  rank_threshold : 0.5
  # How many trees
  num_trees : 100
  # How many samples to use per tree
  num_candidates : 100000
  # Max depth of a tree
  max_depth : 6
  # Minimum number of samples in each leaf
  min_leaf_items : 3000
  # How many times per split to search for an optimal split
  num_tries : 100
  # The max number of features used in each split
  max_features : "sqrt"
  context_transform : identity_transform
  item_transform : identity_transform
  combined_transform : identity_transform
}

# Additive model
additive_model_config {
  trainer: "additive"
  model_output: ${model_name}
  // Name of the special feature that contains the label
  rank_key : "LABEL"
  multiscale : [ 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 64 ]
  // What kind of loss function
  loss : "hinge"
  learning_rate : 0.1
  num_bags : 10
  iterations : 100
  num_bins : 64
  subsample : 0.5
  min_count : 200
  dropout : 0.2
  rank_threshold : 0.0
  smoothing_tolerance : 0.03
  linfinity_cap : 0.0
  linfinity_threshold : 0.01
  context_transform : identity_transform
  item_transform : identity_transform
  combined_transform : identity_transform
  class_weights: [ "-1:1", "1:1" ]
}

param_search {
  # Model type
  model_config : ${model_config}
  # Optimization target
  metric_to_maximize : "!HOLD_F1"
  # Path and prefix used to store all models
  model_name_prefix : ${model_name}
  # Max number of trials in parameter search, each round has one training and one eval
  max_round: 8
  # Strategies to conduct parameter search. "guided" will take all provide values and
  # cross join them. "grid" will take an optional min (first val) and an optional max
  # (second val) and generate equal splits for each parameter based on max_round.
  search_strategy: "guided"
  # List of parameters to tune (defined in model_config). In "guided" stategy, provide
  # all parameters you want to try. In "grid" strategy, provide two optional values:
  # first is a min (default 0), second is max (default 1).
  param_to_tune: [
    {
      name: "lambda"
      val: [0.001, 0.01, 0.1]
    }
    {
      name: "lambda2"
      val: [0.01, 0.06, 0.1]
    }
  ]
  # Example for grid strategy
  #  param_to_tune: [
  #    {
  #      name: "lambda"
  #      val: [0.001, 0.1]
  #    }
  #    {
  #      name: "lambda2"
  #      val: [0.01, 0.1]
  #    }
  #  ]

  # (Optional) Where you want to store the results. If omitted, results will not be stored.
  # Results will be displayed in terminal log regardlessly.
  output: ${prefix}"/paramsearch/"${training_data_version}_${model_version}_${model_type}".txt"
  # (Optional) Where you want to copy the best model to.
  best_model_output: ${model_name}
}
